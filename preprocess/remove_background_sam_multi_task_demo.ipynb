{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available: True\n",
      "CUDA device count: 8\n",
      "Current CUDA device: 0\n",
      "Device name: NVIDIA RTX 6000 Ada Generation\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed A*5wfcQaqfSZtvQ0hKmwjDrwAAAQAAAQ.jpg\n",
      "Processed A*RUTcRqGoadQAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*yhhMRIVoNgIAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*7DHLR7A9-PcAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*B0UFQY5-NWAAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*Ilm_R4vQBwAAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*AcLoQ62XAiEAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*7LqiQ6pid-MAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*zO1xSLQ2HekAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*mn91SptgaVkAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*Vj18TaEJwkYAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*XAoET6NgEiEAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*wsZqTbPRGS8AAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*6rpyT7SHRbEAAAAAAAAAAAAAAQAAAQ.jpg\n",
      "Processed A*qpEoQKj_Er0AAAAAAAAAAAAAAQAAAQ.jpg\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import cv2  \n",
    "import torch  \n",
    "import numpy as np  \n",
    "import supervision as sv  \n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator  \n",
    "\n",
    "class PetSegmentationPreprocessor:  \n",
    "    def __init__(self, model_type=\"vit_h\", checkpoint_path=\"../model/sam_checkpoints/sam_vit_h_4b8939.pth\"):  \n",
    "        # Device configuration  \n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'  \n",
    "        print(f\"Using device: {self.device}\")  \n",
    "        \n",
    "        # Load SAM model  \n",
    "        self.sam = sam_model_registry[model_type](checkpoint=checkpoint_path)  \n",
    "        self.sam.to(device=self.device)  \n",
    "        \n",
    "        # Initialize mask generator with optimized parameters  \n",
    "        self.mask_generator = SamAutomaticMaskGenerator(  \n",
    "            model=self.sam,  \n",
    "            points_per_side=32,  # Increased for more detailed segmentation  \n",
    "            pred_iou_thresh=0.86,  # Higher threshold for quality masks  \n",
    "            stability_score_thresh=0.92,  # Stricter stability criterion  \n",
    "            crop_n_layers=1,  \n",
    "            crop_n_points_downscale_factor=2,  \n",
    "            min_mask_region_area=100,  # Minimum area to consider as a valid mask  \n",
    "        )  \n",
    "\n",
    "    def extract_pet_mask(self, image_path):  \n",
    "        \"\"\"  \n",
    "        Extract pet mask from the image  \n",
    "        Returns:   \n",
    "        - Best pet mask   \n",
    "        - Visualization of masks  \n",
    "        \"\"\"  \n",
    "        # Read image  \n",
    "        image = cv2.imread(image_path)  \n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  \n",
    "\n",
    "        # Generate masks  \n",
    "        masks = self.mask_generator.generate(image_rgb)  \n",
    "        \n",
    "        # Sort masks by area (descending) and score (descending)  \n",
    "        sorted_masks = sorted(  \n",
    "            masks,   \n",
    "            key=lambda x: (x['area'], x['predicted_iou']),   \n",
    "            reverse=True  \n",
    "        )  \n",
    "\n",
    "        # Custom mask visualization  \n",
    "        def create_mask_visualization(image, masks):  \n",
    "            # Create a copy of the image to annotate  \n",
    "            visualization = image.copy()  \n",
    "            \n",
    "            # Draw masks with random colors  \n",
    "            for mask in masks:  \n",
    "                # Generate a random color  \n",
    "                color = np.random.randint(0, 255, 3).tolist()  \n",
    "                \n",
    "                # Create a mask overlay  \n",
    "                mask_overlay = visualization.copy()  \n",
    "                mask_overlay[mask['segmentation']] = color  \n",
    "                \n",
    "                # Blend the overlay  \n",
    "                alpha = 0.5  # Transparency factor  \n",
    "                visualization = cv2.addWeighted(visualization, 1 - alpha, mask_overlay, alpha, 0)  \n",
    "            \n",
    "            return visualization  \n",
    "\n",
    "        # Visualize masks  \n",
    "        mask_visualization = create_mask_visualization(image_rgb, sorted_masks)  \n",
    "\n",
    "        # Select the most promising mask (largest area with high confidence)  \n",
    "        if sorted_masks:  \n",
    "            best_mask = sorted_masks[0]['segmentation']  \n",
    "            return best_mask, mask_visualization  \n",
    "        \n",
    "        return None, image_rgb  \n",
    "\n",
    "    def process_demo_dataset(self, input_dir, output_dir, num_images=10):  \n",
    "        # Create output directories  \n",
    "        os.makedirs(output_dir, exist_ok=True)  \n",
    "        os.makedirs(os.path.join(output_dir, 'masks'), exist_ok=True)  \n",
    "        os.makedirs(os.path.join(output_dir, 'visualizations'), exist_ok=True)  \n",
    "\n",
    "        # Get image files  \n",
    "        image_files = [f for f in os.listdir(input_dir)   \n",
    "                       if f.lower().endswith(('.jpg', '.jpeg', '.png'))]  \n",
    "        \n",
    "        # Limit to first n images  \n",
    "        demo_files = image_files[:num_images]  \n",
    "\n",
    "        # Results tracking  \n",
    "        results = []  \n",
    "\n",
    "        for filename in demo_files:  \n",
    "            input_path = os.path.join(input_dir, filename)  \n",
    "            \n",
    "            try:  \n",
    "                # Extract pet mask  \n",
    "                pet_mask, mask_visualization = self.extract_pet_mask(input_path)  \n",
    "                \n",
    "                if pet_mask is not None:  \n",
    "                    # Original image  \n",
    "                    image = cv2.imread(input_path)  \n",
    "                    \n",
    "                    # Create masked image  \n",
    "                    masked_image = image.copy()  \n",
    "                    masked_image[~pet_mask] = [255, 255, 255]  # White background  \n",
    "                    \n",
    "                    # Save outputs  \n",
    "                    mask_output_path = os.path.join(output_dir, 'masks', filename)  \n",
    "                    cv2.imwrite(mask_output_path, (pet_mask * 255).astype(np.uint8))  \n",
    "                    \n",
    "                    masked_image_path = os.path.join(output_dir, filename)  \n",
    "                    cv2.imwrite(masked_image_path, masked_image)  \n",
    "                    \n",
    "                    # Save mask visualization  \n",
    "                    viz_path = os.path.join(output_dir, 'visualizations', filename)  \n",
    "                    cv2.imwrite(viz_path, mask_visualization)  \n",
    "                    \n",
    "                    # Track results  \n",
    "                    results.append({  \n",
    "                        'filename': filename,  \n",
    "                        'mask_path': mask_output_path,  \n",
    "                        'masked_image_path': masked_image_path,  \n",
    "                        'visualization_path': viz_path  \n",
    "                    })  \n",
    "                    \n",
    "                    print(f\"Processed {filename}\")  \n",
    "                else:  \n",
    "                    print(f\"No mask found for {filename}\")  \n",
    "\n",
    "            except Exception as e:  \n",
    "                print(f\"Error processing {filename}: {e}\")  \n",
    "                # Optional: log the full traceback  \n",
    "                import traceback  \n",
    "                traceback.print_exc()  \n",
    "\n",
    "        return results  \n",
    "\n",
    "def main():  \n",
    "    # Initialize segmentor  \n",
    "    segmentor = PetSegmentationPreprocessor()  \n",
    "    \n",
    "    # Process demo dataset  \n",
    "    demo_results = segmentor.process_demo_dataset(  \n",
    "        input_dir='../dataset/trainset',  \n",
    "        output_dir='../dataset/preprocessed_trainset_demo',  \n",
    "        num_images=15  \n",
    "    )  \n",
    "\n",
    "if __name__ == \"__main__\":  \n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
